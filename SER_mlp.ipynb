{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKNo9RTBj1hA"
   },
   "source": [
    "#Speech Emotion Recognition with MLP Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AztUA74EerMQ"
   },
   "source": [
    "#Dataset\n",
    "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) \n",
    "\n",
    "---\n",
    "File khusus audio\n",
    "\n",
    "File hanya audio dari semua aktor (01-24) tersedia sebagai dua file zip terpisah (masing-masing ~ 200 MB):\n",
    "\n",
    "File ucapan (Audio_Speech_Actors_01-24.zip, 215 MB) berisi 1440 file: 60 percobaan per aktor x 24 aktor = 1440. File lagu (Audio_Song_Actors_01-24.zip, 198 MB) berisi 1012 file: 44 percobaan per aktor x 23 aktor = 1012.\n",
    "\n",
    "Jumlah = 2452\n",
    "\n",
    "Pada percobaan model kali ini hanya file ucapan yang digunakan.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqlY-_LUpD3l"
   },
   "source": [
    "# Import Paket yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fyYSbcJjy7i"
   },
   "outputs": [],
   "source": [
    "import soundfile # untuk membaca file audio\n",
    "import numpy as np\n",
    "import librosa # untuk mengekstrak fitur ucapan\n",
    "import glob\n",
    "import os\n",
    "import pickle # untuk menyimpan model setelah pelatihan\n",
    "from sklearn.model_selection import train_test_split # untuk pelatihan dan pengujian\n",
    "from sklearn.neural_network import MLPClassifier # multi-layer perceptron model\n",
    "from sklearn.metrics import accuracy_score # untuk mengukur seberapa baik model bekerja\n",
    "from sklearn.metrics import classification_report # untuk mengklasifikasi laporan kerja model\n",
    "from sklearn.metrics import confusion_matrix # untuk konfusi matriks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QufSKr1ksJc"
   },
   "source": [
    "Tentukan fungsi extract_feature untuk mengekstrak fitur mfcc, chroma, mel, kontras, dan tonnetz dari file suara.\n",
    "\n",
    "* mfcc: Mel Frequency Cepstral Coefficient, mewakili spektrum daya jangka pendek suatu suara\n",
    "* chroma: Berkaitan dengan 12 kelas nada yang berbeda\n",
    "* mel: Frekuensi Spektogram Mel\n",
    "* kontras: perbedaan yang nyata apabila diperbandingkan\n",
    "* tonnetz: harmoni nada\n",
    "\n",
    "misalnya:\n",
    "`fitur = extract_feature (jalur, mel = True, mfcc = True, contrast = True, tonnetz = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwB6D_vLpOoR"
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xKzPyVcjvyT"
   },
   "source": [
    "definisikan kamus untuk menampung angka dan emosi yang tersedia dalam kumpulan data RAVDESS, dan daftar untuk menampung semua 8 emosi- netral, tenang, bahagia, sedih, marah, takut, jijik, terkejut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgwcKBQzpdgM"
   },
   "outputs": [],
   "source": [
    "# all emotions on RAVDESS dataset\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# we allow only these emotions ( feel free to tune this on your need )\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VjDiYuC3G-D"
   },
   "source": [
    "# Muat data dan ekstrak fitur untuk setiap file suara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2axyBFDqI1A"
   },
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    X, y = [], []\n",
    "    for file in glob.glob(\"C:\\\\Users\\\\#Ssc_SMAN9BLK\\\\ravdess data\\\\Actor_*\\\\*.wav\"):\n",
    "        # get the base name of the audio file\n",
    "        basename = os.path.basename(file)\n",
    "        # get the emotion label\n",
    "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "        # we allow only AVAILABLE_EMOTIONS we set\n",
    "        if emotion not in AVAILABLE_EMOTIONS:\n",
    "            continue\n",
    "        # extract speech features\n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True, contrast=True, tonnetz=True)\n",
    "        # add to data\n",
    "        X.append(features)\n",
    "        y.append(emotion)\n",
    "    # split the data to training and testing and return it\n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKhGTlqpqOAr"
   },
   "source": [
    "# Pisahkan Set Data\n",
    "Membagi data menjadi data pelatihan dan data pengujian! data pengujian 25% dari semuanya dan gunakan fungsi load_data untuk mengatur pengukuran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a92bN5vAqRb2"
   },
   "outputs": [],
   "source": [
    "# load RAVDESS dataset, 75% training 25% testing\n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46eeiQbYqT7p"
   },
   "source": [
    "#set data pelatihan dan pengujian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_MXFh4lwqYaC",
    "outputId": "eb020e32-a754-4510-97b1-8aaddfba58de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 168)\n"
     ]
    }
   ],
   "source": [
    "#tampilkan bentuk set data pelatihan dan pengujian\n",
    "print((X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmwRPZe7qey5"
   },
   "source": [
    "# Jumlah fitur yang diekstrak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "H3C6czeDqgxX",
    "outputId": "8625bb60-0a8b-4f66-9b50-88a536ea8b5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Jumlah sampel data pelatihan: 504\n",
      "[+] Jumlah sampel data pengujian: 168\n",
      "[+] Jumlah fitur: 193\n"
     ]
    }
   ],
   "source": [
    "# jumlah sampel dalam data pelatihan\n",
    "print(\"[+] Jumlah sampel data pelatihan:\", X_train.shape[0])\n",
    "# jumlah sampel dalam data pengujian\n",
    "print(\"[+] Jumlah sampel data pengujian:\", X_test.shape[0])\n",
    "# jumlah fitur yang digunakan\n",
    "# ini adalah vektor fitur yang diekstrak \n",
    "# menggunakan extract_features() function\n",
    "print(\"[+] Jumlah fitur:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEvGnx7r3W7f"
   },
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvggD94ZqmAY"
   },
   "outputs": [],
   "source": [
    "# model terbaik, ditentukan oleh pencarian grid\n",
    "model_params = {\n",
    "    'alpha': 0.01,\n",
    "    'batch_size': 300,\n",
    "    'epsilon': 1e-08, \n",
    "    'hidden_layer_sizes': (300,), \n",
    "    'learning_rate': 'adaptive', \n",
    "    'max_iter': 500, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cG4YLLXGqpAb"
   },
   "source": [
    "#menginisialisasi MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "9OfJEVsDqrbY",
    "outputId": "b488b813-c7c9-475e-e527-9428af91ae5c"
   },
   "outputs": [],
   "source": [
    "# menginisialisasi Multi Layer Perceptron classifier\n",
    "# dengan parameter terbaik\n",
    "model = MLPClassifier(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cG4YLLXGqpAb"
   },
   "source": [
    "#lakukan pelatihan pada model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "9OfJEVsDqrbY",
    "outputId": "b488b813-c7c9-475e-e527-9428af91ae5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=300, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pelatihan model\n",
    "print(\"[*] Training the model...\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDC7AkAt21EF"
   },
   "source": [
    "# Memprediksi keakuratan model kita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2Kzw2Emqt1p"
   },
   "source": [
    "Mari kita prediksi nilai untuk data pengujian. Ini memberi kita y_pred (emosi yang diprediksi untuk fitur dalam set data pengujian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNVNDVnBqw1z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'angry', 'happy', 'sad', 'happy', 'angry', 'happy',\n",
       "       'angry', 'angry', 'happy', 'sad', 'neutral', 'neutral', 'neutral',\n",
       "       'sad', 'sad', 'happy', 'angry', 'sad', 'sad', 'angry', 'happy',\n",
       "       'neutral', 'happy', 'sad', 'happy', 'angry', 'angry', 'neutral',\n",
       "       'angry', 'sad', 'sad', 'sad', 'angry', 'neutral', 'sad', 'sad',\n",
       "       'happy', 'neutral', 'neutral', 'sad', 'angry', 'angry', 'neutral',\n",
       "       'angry', 'sad', 'happy', 'neutral', 'neutral', 'happy', 'sad',\n",
       "       'neutral', 'happy', 'happy', 'sad', 'angry', 'angry', 'happy',\n",
       "       'angry', 'angry', 'neutral', 'sad', 'sad', 'sad', 'happy',\n",
       "       'neutral', 'neutral', 'angry', 'happy', 'angry', 'happy', 'happy',\n",
       "       'sad', 'angry', 'angry', 'happy', 'angry', 'happy', 'sad', 'angry',\n",
       "       'sad', 'sad', 'happy', 'angry', 'happy', 'neutral', 'sad', 'sad',\n",
       "       'sad', 'angry', 'sad', 'neutral', 'sad', 'angry', 'happy', 'angry',\n",
       "       'angry', 'sad', 'sad', 'happy', 'neutral', 'sad', 'angry', 'happy',\n",
       "       'sad', 'angry', 'angry', 'angry', 'angry', 'sad', 'angry', 'sad',\n",
       "       'angry', 'happy', 'sad', 'sad', 'happy', 'angry', 'happy', 'happy',\n",
       "       'neutral', 'happy', 'sad', 'angry', 'happy', 'neutral', 'angry',\n",
       "       'sad', 'angry', 'angry', 'angry', 'angry', 'happy', 'angry',\n",
       "       'happy', 'angry', 'angry', 'angry', 'angry', 'angry', 'neutral',\n",
       "       'angry', 'sad', 'happy', 'happy', 'sad', 'angry', 'sad', 'angry',\n",
       "       'happy', 'angry', 'sad', 'angry', 'sad', 'angry', 'neutral',\n",
       "       'happy', 'happy', 'neutral', 'angry', 'happy', 'neutral', 'happy',\n",
       "       'happy', 'happy', 'angry', 'sad', 'angry'], dtype='<U7')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memprediksi 25% data untuk mengukur seberapa baik kita\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njU6Gs6jqzkg"
   },
   "source": [
    "Untuk menghitung akurasi model kita, kita akan memanggil fungsi akurasi_score () yang kita impor dari sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_sDEv4K1q1VA",
    "outputId": "b701c4ab-54b0-4173-ebe5-da659c5dd44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.14%\n"
     ]
    }
   ],
   "source": [
    "# menghitung akurasi\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGdh6fh02hFc"
   },
   "source": [
    "#Laporan klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "2xreI8SSq6Rc",
    "outputId": "e7a791de-bbc6-47d7-fdbe-ab80a0f8e53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.95      0.89      0.92        61\n",
      "       happy       0.74      0.78      0.76        41\n",
      "     neutral       0.71      0.81      0.76        21\n",
      "         sad       0.80      0.78      0.79        45\n",
      "\n",
      "    accuracy                           0.82       168\n",
      "   macro avg       0.80      0.81      0.80       168\n",
      "weighted avg       0.83      0.82      0.82       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZZZBmK32ksS"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "Y2IEjtiTtl-f",
    "outputId": "f5c2e30f-b101-4728-9547-f68b4774cbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  5  1  1]\n",
      " [ 2 32  1  6]\n",
      " [ 1  1 17  2]\n",
      " [ 0  5  5 35]]\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test,y_pred)\n",
    "print (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpan modelnya\n",
    "# buat direktori hasil jika belum ada\n",
    "if not os.path.isdir(\"result\"):\n",
    "    os.mkdir(\"result\")\n",
    "\n",
    "pickle.dump(model, open(\"result/mlp_classifier.model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sekian"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FinalSER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
